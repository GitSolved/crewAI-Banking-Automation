# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Repository Overview

This is a crewAI learning course repository containing multiple multi-agent AI automation projects. Each subdirectory demonstrates a complete, self-contained application using the crewAI framework to orchestrate autonomous AI agents for specific business workflows.

## Project Structure

All projects are located in the `training/` directory. Each subdirectory is a standalone Jupyter notebook-based project:
- **training/Article_Automation**: Research and write articles using sequential agent collaboration
- **training/Customer_Outreach_Campaign**: Automate customer engagement campaigns with tailored messaging
- **training/Customer_Support_Automation**: Handle customer support inquiries with AI agents
- **training/Event_Planning_Automation**: Plan and coordinate events
- **training/Financial_Analysis**: Perform stock analysis using hierarchical agent collaboration
- **training/Job_Application_Booster**: Tailor resumes and prepare interview materials

Each project directory contains:
- A main `.ipynb` notebook with the complete workflow
- A `requirements.txt` file with all project-specific dependencies
- Output files (`.md` format) generated by agent tasks
- Some projects include additional resources (e.g., `instructions/` subdirectories with templates)

## crewAI Architecture Fundamentals

### Agent Creation Pattern
All projects follow the same Agent instantiation pattern:

```python
from crewai import Agent

agent = Agent(
    role="Specific Role Name",
    goal="Clear objective the agent should achieve",
    backstory="Context about the agent's expertise and function",
    tools=[tool1, tool2],  # Optional: crewAI or LangChain tools
    verbose=True,
    allow_delegation=True  # Enable for hierarchical processes
)
```

### Task Definition Pattern
Tasks require three mandatory fields:

```python
from crewai import Task

task = Task(
    description="Detailed description with {variable_placeholders}",
    expected_output="Specific format and content expectations",
    agent=assigned_agent,
    output_file="output.md",  # Optional: save results to file
    context=[previous_task],  # Optional: dependencies on other tasks
    async_execution=True  # Optional: for parallel execution
)
```

### Crew Assembly and Execution
Two primary collaboration patterns are used:

**Sequential Process** (default):
```python
from crewai import Crew

crew = Crew(
    agents=[agent1, agent2, agent3],
    tasks=[task1, task2, task3],  # Executed in order
    verbose=True,
    memory=True  # Optional: enable agent memory
)

result = crew.kickoff(inputs={"variable": "value"})
```

**Hierarchical Process** (with auto-created manager):
```python
from crewai import Crew, Process
from langchain_openai import ChatOpenAI

crew = Crew(
    agents=[agent1, agent2, agent3],
    tasks=[task1, task2, task3],
    process=Process.hierarchical,
    manager_llm=ChatOpenAI(model="gpt-3.5-turbo"),
    verbose=True
)
```

## Development Workflow

### Environment Setup
1. Ensure Python version is between 3.10 and 3.13 (inclusive)
2. Install dependencies for a specific project:
   ```bash
   cd training/<project_directory>
   pip install -r requirements.txt
   ```
   Note: Some projects require both `crewai` and `crewai_tools` packages

### Required API Keys
Projects require environment variables to be set before execution:

```python
import os
os.environ["OPENAI_API_KEY"] = "your-key"
os.environ["OPENAI_MODEL_NAME"] = "gpt-4-turbo"  # or gpt-3.5-turbo
os.environ["SERPER_API_KEY"] = "your-key"  # For web search tools
```

### Running Projects
1. Navigate to the project directory: `cd training/<project_name>`
2. Launch Jupyter: `jupyter notebook` or `jupyter lab`
3. Open the `.ipynb` notebook file
4. Set required API keys in environment variables (in the notebook cells)
5. Execute cells sequentially from top to bottom
6. Review generated output files (`.md` files) in the project directory

**Common Commands:**
```bash
# Install Jupyter if not already installed
pip install jupyter

# Launch Jupyter Notebook
jupyter notebook

# Launch Jupyter Lab (recommended)
jupyter lab
```

### Testing Individual Components
To test agents or tasks in isolation:

```python
# Test a single task
task_output = task.execute()

# Inspect agent configuration
print(agent.role, agent.goal, agent.tools)
```

## Common Tools Used

### crewAI Tools
- `SerperDevTool()`: Web search capabilities (requires SERPER_API_KEY)
- `ScrapeWebsiteTool()`: Extract content from URLs
- `FileReadTool(file_path="path.md")`: Read local files
- `MDXSearchTool(mdx="path.md")`: Semantic search within markdown files

### Integration Notes
- Tasks can reference variables using `{variable_name}` syntax
- Variables are provided via the `inputs` parameter in `crew.kickoff()`
- Task outputs can serve as context for subsequent tasks using the `context` parameter
- `async_execution=True` allows tasks to run in parallel when they don't depend on each other

## Key Concepts

### Agent Collaboration Modes
- **Sequential**: Tasks execute in order, each receiving the previous task's output
- **Hierarchical**: A manager agent delegates and coordinates work among specialist agents
- **Parallel**: Independent tasks execute simultaneously using `async_execution=True`

### Memory System
When `memory=True` is set on a Crew:
- Short-term memory: Recent task outputs and interactions
- Long-term memory: Learning from past executions
- Entity memory: Recognition of key entities across conversations

### Task Dependencies
Tasks can be chained using the `context` parameter:
```python
task3 = Task(
    description="...",
    expected_output="...",
    agent=agent3,
    context=[task1, task2]  # Will wait for these to complete
)
```

## Project-Specific Patterns

### Article_Automation (training/Article_Automation)
- **Pattern**: Sequential collaboration
- **Agents**: Content Planner → Content Writer → Editor
- **Key Learning**: Basic sequential task flow with context passing between agents
- **Output**: Blog article in markdown format

### Job_Application_Booster (training/Job_Application_Booster)
- **Pattern**: Parallel + Sequential hybrid
- **Agents**: Tech Job Researcher, Personal Profiler, Resume Strategist, Interview Preparer
- **Key Learning**: Async task execution where research tasks (`async_execution=True`) run in parallel, then sequential tasks use combined outputs via `context` parameter
- **Output**: Tailored resume and interview preparation materials

### Financial_Analysis (training/Financial_Analysis)
- **Pattern**: Hierarchical collaboration
- **Agents**: Data Analyst, Trading Strategy Developer, Trade Advisor, Risk Advisor
- **Key Learning**: Manager-driven delegation where a manager LLM (`Process.hierarchical`) coordinates specialist agents
- **Output**: Comprehensive financial analysis report

### Customer_Outreach_Campaign (training/Customer_Outreach_Campaign)
- **Pattern**: Sequential with file-based resources
- **Key Learning**: Using external instruction files from `instructions/` directory to guide agent behavior
- **Output**: Personalized outreach campaigns

## Modifying Projects

When creating or modifying agents:
1. Define clear, specific roles (more specific = better performance)
2. Write actionable goals that guide decision-making
3. Provide detailed backstory for context
4. Assign only relevant tools to avoid agent confusion

When creating or modifying tasks:
1. Use detailed descriptions with step-by-step instructions
2. Specify exact output format in `expected_output`
3. Use variable placeholders for dynamic inputs
4. Set appropriate task dependencies via `context`
